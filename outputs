# Run the full pipeline

# This will:

#   1. Download data from SQL (or load from ES)

#   2. Run NLP enrichment with spaCy

#   3. Build sliding windows for each SID

#   4. Train models for H1 and H2 horizons

#   5. Generate predictions

#   6. Build RAG embeddings (optional)

â€‹

state, pipeline, rag = run_pipeline(

    sql_download=config.sql_download,

    enable_nlp=config.enable_nlp,

    build_models=config.build_models,

    run_predictions=config.run_predictions,

    build_rag=config.build_rag,

)

WARNING: spaCy GPU requested but not available. Using CPU.
[CONN] 	Elasticsearch connection established.
[CONN] 	SQL connection established.
[CONN] 	GPT client initialized.
[EMBD] 	Loading embedding model 'BAAI/bge-large-en-v1.5' to cuda
[EMBD] 	Embedding model loaded with dim 1024
[SQL] 	29304 rows downloaded and stored in state.details_df.
[ES] 	Indexed 29304 documents to 'scorecard_details' with 0 errors.
[PIPE] 	Completed all Downloads from SQL or ES
[ES] 	Indexed 29273 documents to 'scorecard_enriched' with 0 errors.
[ES] 	Indexed 25956 documents to 'scorecard_sid_history' with 0 errors.
[PIPE] 	Completed all Text Prep Steps
[PIPE] 	Training models for 2 horizons: ['H1', 'H2']
[PIPE] 	=== Starting Horizon H1 ===
[DATA] 	[H1] Filtered to 25040 trainable rows with total_notes >= 5 and valid target (0/1/2) 3.5% culled
[MODL] 	[H1] Rehydrated best model: H1 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}
[ML] 	[H1] Best model: H1 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}
[PIPE] 	=== Starting Horizon H2 ===
[DATA] 	[H2] Filtered to 24185 trainable rows with total_notes >= 5 and valid target (0/1/2) 6.8% culled
[MODL] 	[H2] Rehydrated best model: H2 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}
[ML] 	[H2] Best model: H2 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}
[ES] 	Indexed 25956 documents to 'scorecard_predictions' with 0 errors.
[ML] 	H1 predictions uploaded to 'scorecard_predictions'
[ES] 	Indexed 25956 documents to 'scorecard_predictions_h2' with 0 errors.
[ML] 	H2 predictions uploaded to 'scorecard_predictions_h2'

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_4211/2615945988.py in ?()
      6 #   4. Train models for H1 and H2 horizons
      7 #   5. Generate predictions
      8 #   6. Build RAG embeddings (optional)
      9 
---> 10 state, pipeline, rag = run_pipeline(
     11     sql_download=config.sql_download,
     12     enable_nlp=config.enable_nlp,
     13     build_models=config.build_models,

~/silver-iguana/spark_jan/scorecard/main.py in ?(sql_download, enable_nlp, build_models, run_predictions, build_rag)
     64         state=state,
     65         conn=conn,
     66         modeler=modeler
     67     )
---> 68     pipeline.run()
     69 
     70     # Initialize RAG (optional)
     71     rag = ScoreCardRag(config=config, state=state, conn=conn)

~/silver-iguana/spark_jan/scorecard/pipeline.py in ?(self)
     36     def run(self) -> None:
     37         """Execute the full pipeline."""
     38         self._stage_1_download()
     39         self._stage_2_text_enrichment()
---> 40         self._stage_3_modeling_and_prediction()

~/silver-iguana/spark_jan/scorecard/pipeline.py in ?(self)
    174                 )
    175                 self.conn.report("ML", "H2 predictions uploaded to 'scorecard_predictions_h2'")
    176 
    177         # Merge all horizon predictions into complete_df
--> 178         self.modeler.merge_data()

~/silver-iguana/spark_jan/scorecard/modeling.py in ?(self)
    562         """
    563         enriched_df = self.state.enriched_df.copy()
    564 
    565         # Start with H1 predictions (fall back to legacy location if needed)
--> 566         h1_df = self.state.predictions_df_by_horizon.get(1) or self.state.predictions_df
    567 
    568         if h1_df is None:
    569             self.conn.report("JOIN", "No H1 predictions available for merge")

~/.local/lib/python3.11/site-packages/pandas/core/generic.py in ?(self)
   1575     @final
   1576     def __nonzero__(self) -> NoReturn:
-> 1577         raise ValueError(
   1578             f"The truth value of a {type(self).__name__} is ambiguous. "
   1579             "Use a.empty, a.bool(), a.item(), a.any() or a.all()."
   1580         )

ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
