{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreCard ML Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the refactored ScoreCard package with multi-horizon prediction support.\n",
    "\n",
    "**Horizons:**\n",
    "- **H1**: Predict the next scorecard (1 step ahead)\n",
    "- **H2**: Predict the scorecard after next (2 steps ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "Supported horizons: ['H1', 'H2']\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the scorecard package\n",
    "from scorecard import (\n",
    "    ScoreCardConfig,\n",
    "    ScoreCardState,\n",
    "    ConnectionManager,\n",
    "    ScoreCardTextPrep,\n",
    "    ScoreCardModeling,\n",
    "    ScoreCardPipeline,\n",
    "    ScoreCardRag,\n",
    "    Horizon,\n",
    "    SUPPORTED_HORIZONS,\n",
    "    run_pipeline,\n",
    ")\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"Supported horizons: {[f'H{int(h)}' for h in SUPPORTED_HORIZONS]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Configure the pipeline settings. You can customize paths, enable/disable stages, and set model parameters.\n",
    "\n",
    "**Note:** File paths are automatically resolved relative to the package location, so you can run this notebook from any directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration created:\n",
      "  - SQL Download: True\n",
      "  - Build Models: True\n",
      "  - Model Matrix JSON: /home/jovyan/silver-iguana/spark_jan/prompts/model_matrix.json\n",
      "  - H1 Model Key: complete_main_words_only | no_downsample_weighted ...\n",
      "  - H2 Model Key: complete_main_words_only | no_downsample_weighted ...\n"
     ]
    }
   ],
   "source": [
    "# Create configuration with custom settings\n",
    "config = ScoreCardConfig(\n",
    "    # === Data Sources ===\n",
    "    sql_download=True,          # Set False to load from Elasticsearch instead\n",
    "    \n",
    "    # === Pipeline Stages ===\n",
    "    enable_nlp=True,            # Run spaCy NLP enrichment\n",
    "    build_models=True,          # Train ML models\n",
    "    run_predictions=True,       # Generate predictions\n",
    "    build_rag=True,             # Build RAG embeddings for GPT\n",
    "    \n",
    "    # === Model Configuration ===\n",
    "    # Use predetermined model keys (fast) or set to None for grid search\n",
    "    default_model_key_h1=\"complete_main_words_only | no_downsample_weighted | count | {0: 0.5, 1: 1.35, 2: 1.15}\",\n",
    "    default_model_key_h2=\"complete_main_words_only | no_downsample_weighted | count | {0: 0.5, 1: 1.35, 2: 1.15}\",\n",
    "    \n",
    "    # === Training Settings ===\n",
    "    training_length=5,          # Minimum notes needed per SID for training\n",
    ")\n",
    "\n",
    "print(\"Configuration created:\")\n",
    "print(f\"  - SQL Download: {config.sql_download}\")\n",
    "print(f\"  - Build Models: {config.build_models}\")\n",
    "print(f\"  - Model Matrix JSON: {config.model_matrix_json}\")\n",
    "print(f\"  - H1 Model Key: {config.default_model_key_h1[:50]}...\")\n",
    "print(f\"  - H2 Model Key: {config.default_model_key_h2[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify File Paths\n",
    "\n",
    "Check that all required config files are accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Path Verification:\n",
      "============================================================\n",
      "  ✓ Model Matrix JSON: /home/jovyan/silver-iguana/spark_jan/prompts/model_matrix.json\n",
      "  ✓ SQL Query File: /home/jovyan/silver-iguana/spark_jan/prompts/sql_query.txt\n",
      "  ✓ GPT Prompt: /home/jovyan/silver-iguana/spark_jan/prompts/GPT_Prompt.txt\n",
      "\n",
      "All files found! Ready to run pipeline.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files_to_check = [\n",
    "    (\"Model Matrix JSON\", config.model_matrix_json),\n",
    "    (\"SQL Query File\", config.sql_query_file),\n",
    "    (\"GPT Prompt\", config.gpt_prompt_location),\n",
    "]\n",
    "\n",
    "print(\"File Path Verification:\")\n",
    "print(\"=\" * 60)\n",
    "all_ok = True\n",
    "for name, path in files_to_check:\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"✓\" if exists else \"✗ MISSING\"\n",
    "    print(f\"  {status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\nAll files found! Ready to run pipeline.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Some files are missing. Check your prompts/ folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the Full Pipeline\n",
    "\n",
    "The `run_pipeline()` function handles all initialization and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] \tInitializing ScoreCardState...\n",
      "[INIT] \t==================================================\n",
      "[INIT] \tLoading model matrices from: /home/jovyan/silver-iguana/spark_jan/prompts/model_matrix.json\n",
      "[INIT] \t  -> 3 feature sets\n",
      "[INIT] \t  -> 3 sampling strategies\n",
      "[INIT] \t  -> 1 vectorization configs\n",
      "[INIT] \t  -> 3 class weight configs\n",
      "[INIT] \tInitializing spaCy model: en_core_web_trf\n",
      "[INIT] \t  -> Activating GPU for spaCy...\n",
      "[INIT] \t  -> WARNING: GPU requested but not available. Using CPU.\n",
      "[INIT] \t  -> Loading model 'en_core_web_trf'...\n",
      "[INIT] \t  -> spaCy model loaded in 2.4s\n",
      "[INIT] \tLoading SQL query from: /home/jovyan/silver-iguana/spark_jan/prompts/sql_query.txt\n",
      "[INIT] \t  -> SQL query loaded (1475 chars)\n",
      "[INIT] \tLoading GPT prompt from: /home/jovyan/silver-iguana/spark_jan/prompts/GPT_Prompt.txt\n",
      "[INIT] \t  -> GPT prompt loaded (2236 chars)\n",
      "[INIT] \t==================================================\n",
      "[INIT] \tScoreCardState initialization complete!\n",
      "[CONN] \tConnectionManager initializing...\n",
      "[CONN] \t----------------------------------------\n",
      "[CONN] \tConnecting to Elasticsearch: http://localhost:9200\n",
      "[CONN] \t  -> Elasticsearch connection established!\n",
      "[CONN] \tConnecting to SQL Server: Nestler.us.lmco.com\n",
      "[CONN] \t  -> Database: SubcontractScorecard\n",
      "[CONN] \t  -> SQL connection established!\n",
      "[CONN] \tInitializing GPT client: https://api.ai.us.lmco.com/v1/\n",
      "[CONN] \t  -> OPENAI_API_KEY: SET\n",
      "[CONN] \t  -> GPT client initialized!\n",
      "[EMBD] \tLoading embedding model: BAAI/bge-large-en-v1.5\n",
      "[EMBD] \t  -> Device: cuda\n",
      "[EMBD] \t  -> CUDA device count: 2\n",
      "[EMBD] \t  -> CUDA device name: NVIDIA A100-SXM4-80GB\n",
      "[EMBD] \t  -> Embedding model loaded in 8.9s (dim=1024)\n",
      "[CONN] \t----------------------------------------\n",
      "[CONN] \tAll connections established!\n",
      "[PIPE] \t============================================================\n",
      "[PIPE] \tSCORECARD PIPELINE STARTING\n",
      "[PIPE] \t============================================================\n",
      "[PIPE] \tConfig: sql_download=True, enable_nlp=True\n",
      "[PIPE] \tConfig: build_models=True, run_predictions=True\n",
      "[PIPE] \tConfig: build_rag=True\n",
      "[PIPE] \t----------------------------------------\n",
      "[PIPE] \tSTAGE 1: DATA DOWNLOAD\n",
      "[PIPE] \t----------------------------------------\n",
      "[PIPE] \tSource: SQL Server\n",
      "[SQL] \t29312 rows downloaded and stored in state.details_df.\n",
      "[ES] \tIndexed 29312 documents to 'scorecard_details' with 0 errors.\n",
      "[PIPE] \tStage 1 complete in 32.3s - 29312 rows loaded\n",
      "[PIPE] \t----------------------------------------\n",
      "[PIPE] \tSTAGE 2: NLP ENRICHMENT & WINDOW GENERATION\n",
      "[PIPE] \t----------------------------------------\n",
      "[PIPE] \tRunning fresh NLP enrichment (enable_nlp=True)\n",
      "[NLP] \tStarting NLP enrichment on 29312 rows\n",
      "[NLP] \tStep 1/6: Generating sid_key identifiers...\n",
      "[NLP] \t  -> 29312 notes across 1245 unique SIDs\n",
      "[NLP] \tStep 2/6: Cleaning HTML from Scorecard_Note...\n",
      "[NLP] \t  -> Avg text length after cleaning: 714 chars\n",
      "[NLP] \tStep 3/6: Running spaCy NLP pipeline (this may take a while)...\n",
      "[NLP] \t  -> spaCy processed 29312 documents in 10737.6s (2.7 docs/sec)\n",
      "[NLP] \tStep 4/6: Extracting verbs, adjectives, noun_chunks...\n",
      "[NLP] \t  -> Extracted features for 29312 notes\n",
      "[NLP] \tStep 5/6: Mapping color labels to numeric targets...\n",
      "[NLP] \t  -> Dropped 31 rows with missing 'Overall'\n",
      "[NLP] \t  -> Color distribution: G=23924, Y=4324, R=1033\n",
      "[NLP] \tStep 6/6: Computing next_color_code and note_history...\n",
      "[NLP] \tNLP enrichment complete! 29281 rows enriched in 10770.1s\n",
      "[WIND] \tBuilding SID history windows from 29281 enriched notes\n",
      "[WIND] \tStep 1/3: Grouping notes by SID...\n",
      "[WIND] \t  -> 1243 unique SIDs (avg 23.6 notes per SID)\n",
      "[WIND] \tStep 2/3: Generating sliding windows for each SID...\n",
      "[WIND] \tStep 3/3: Building sid_df DataFrame...\n",
      "[WIND] \tWindow generation complete in 3.9s\n",
      "[WIND] \t  -> Total windows: 25964\n",
      "[WIND] \t  -> H1 trainable: 25048 (96.5%)\n",
      "[WIND] \t  -> H2 trainable: 24193 (93.2%)\n",
      "[WIND] \t  -> Skipped SIDs (< 4 notes): 327\n",
      "[PIPE] \tUploading enriched data to Elasticsearch...\n",
      "[ES] \tIndexed 29281 documents to 'scorecard_enriched' with 0 errors.\n",
      "[ES] \tIndexed 25964 documents to 'scorecard_sid_history' with 0 errors.\n",
      "[PIPE] \tStage 2 complete in 10801.3s\n",
      "[PIPE] \t  -> enriched_df: 29281 rows\n",
      "[PIPE] \t  -> sid_df: 25964 windows\n",
      "[PIPE] \t----------------------------------------\n",
      "[PIPE] \tSTAGE 3: MODEL TRAINING & PREDICTION\n",
      "[PIPE] \t----------------------------------------\n",
      "[PIPE] \tBuilding model configuration grid...\n",
      "[PIPE] \t  -> 9 model configurations in grid\n",
      "[PIPE] \tTraining models for 2 horizons: ['H1', 'H2']\n",
      "[PIPE] \t=== Starting Horizon H1 ===\n",
      "[DATA] \t[H1] Filtered to 25048 trainable rows with total_notes >= 5 and valid target (0/1/2) 3.5% culled\n",
      "[MODL] \t[H1] Rehydrated best model: H1 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "[MODL] \t[H1] --------------------------------------------------\n",
      "[MODL] \t[H1] MODEL EVALUATION RESULTS\n",
      "[MODL] \t[H1] --------------------------------------------------\n",
      "[MODL] \t[H1] Accuracy: 0.9651 (96.51%)\n",
      "[MODL] \t[H1] False Negatives: 83 total\n",
      "[MODL] \t[H1]   2 → 0: 0\n",
      "[MODL] \t[H1]   2 → 1: 14\n",
      "[MODL] \t[H1]   1 → 0: 69\n",
      "[MODL] \t[H1] Confusion Matrix (rows=actual, cols=predicted):\n",
      "[MODL] \t[H1]              Green  Yellow    Red\n",
      "[MODL] \t[H1]   Green     3926      79       5\n",
      "[MODL] \t[H1]   Yellow      69     724       8\n",
      "[MODL] \t[H1]   Red          0      14     185\n",
      "[MODL] \t[H1] Class Weights: {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "[MODL] \t[H1] --------------------------------------------------\n",
      "[ML] \t[H1] Best model: H1 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "[PIPE] \t=== Starting Horizon H2 ===\n",
      "[DATA] \t[H2] Filtered to 24193 trainable rows with total_notes >= 5 and valid target (0/1/2) 6.8% culled\n",
      "[MODL] \t[H2] Rehydrated best model: H2 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "[MODL] \t[H2] --------------------------------------------------\n",
      "[MODL] \t[H2] MODEL EVALUATION RESULTS\n",
      "[MODL] \t[H2] --------------------------------------------------\n",
      "[MODL] \t[H2] Accuracy: 0.9731 (97.31%)\n",
      "[MODL] \t[H2] False Negatives: 57 total\n",
      "[MODL] \t[H2]   2 → 0: 3\n",
      "[MODL] \t[H2]   2 → 1: 8\n",
      "[MODL] \t[H2]   1 → 0: 46\n",
      "[MODL] \t[H2] Confusion Matrix (rows=actual, cols=predicted):\n",
      "[MODL] \t[H2]              Green  Yellow    Red\n",
      "[MODL] \t[H2]   Green     3789      66       0\n",
      "[MODL] \t[H2]   Yellow      46     733       7\n",
      "[MODL] \t[H2]   Red          3       8     187\n",
      "[MODL] \t[H2] Class Weights: {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "[MODL] \t[H2] --------------------------------------------------\n",
      "[ML] \t[H2] Best model: H2 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "[ES] \tIndexed 25964 documents to 'scorecard_predictions' with 0 errors.\n",
      "[ML] \tH1 predictions uploaded to 'scorecard_predictions'\n",
      "[ES] \tIndexed 25964 documents to 'scorecard_predictions_h2' with 0 errors.\n",
      "[ML] \tH2 predictions uploaded to 'scorecard_predictions_h2'\n",
      "[PIPE] \tMerging predictions from all horizons...\n",
      "[JOIN] \tMerged H1 and H2 predictions. Final shape: (29281, 61)\n",
      "[PIPE] \tStage 3 complete in 991.3s (16.5 min)\n",
      "[PIPE] \t  -> complete_df: 29281 rows\n",
      "[PIPE] \t  -> H1 predictions: {'Green': 20864, 'Yellow': 4087, 'Red': 1013}\n",
      "[PIPE] \t  -> H2 predictions: {'Green': 20831, 'Yellow': 4128, 'Red': 1005}\n",
      "[PIPE] \t============================================================\n",
      "[PIPE] \tPIPELINE COMPLETE in 11826.3s (197.1 min)\n",
      "[PIPE] \t============================================================\n",
      "[EMBD] \tEncoding 29281 notes for embedding on cuda...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0ab97a78fc4cc8876037c7becdbfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EMBD] \tToken count stats: {\n",
      "  \"count\": 29281.0,\n",
      "  \"mean\": 190.2069601448038,\n",
      "  \"std\": 328.3067443233864,\n",
      "  \"min\": 0.0,\n",
      "  \"25%\": 32.0,\n",
      "  \"50%\": 95.0,\n",
      "  \"75%\": 243.0,\n",
      "  \"max\": 14083.0\n",
      "}\n",
      "[ES] \tDeleted existing index 'scorecard_rag_notes'\n",
      "[ES] \tCreated index 'scorecard_rag_notes' with vector mapping\n",
      "[ES] \tIndexed 29281 documents to 'scorecard_rag_notes'\n"
     ]
    }
   ],
   "source": [
    "# Run the full pipeline\n",
    "# This will:\n",
    "#   1. Download data from SQL (or load from ES)\n",
    "#   2. Run NLP enrichment with spaCy\n",
    "#   3. Build sliding windows for each SID\n",
    "#   4. Train models for H1 and H2 horizons\n",
    "#   5. Generate predictions\n",
    "#   6. Build RAG embeddings (optional)\n",
    "\n",
    "state, pipeline, rag = run_pipeline(\n",
    "    sql_download=config.sql_download,\n",
    "    enable_nlp=config.enable_nlp,\n",
    "    build_models=config.build_models,\n",
    "    run_predictions=config.run_predictions,\n",
    "    build_rag=config.build_rag,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENRICHED DATAFRAME\n",
      "============================================================\n",
      "Shape: (29281, 42)\n",
      "Columns: ['SID', 'Scorecard_Detail_Note_SID', 'Scorecard_Note', 'Note_Year', 'Note_Month', 'PO_Number', 'PO_Contract_Type', 'PO_Complexity_Level', 'PO_Lifecycle_Phase', 'Supplier_Name']...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>Scorecard_Detail_Note_SID</th>\n",
       "      <th>Scorecard_Note</th>\n",
       "      <th>Note_Year</th>\n",
       "      <th>Note_Month</th>\n",
       "      <th>PO_Number</th>\n",
       "      <th>PO_Contract_Type</th>\n",
       "      <th>PO_Complexity_Level</th>\n",
       "      <th>PO_Lifecycle_Phase</th>\n",
       "      <th>Supplier_Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Archive_Indicator</th>\n",
       "      <th>sid_key</th>\n",
       "      <th>pre_scrub_text</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>noun_chunks</th>\n",
       "      <th>main_words</th>\n",
       "      <th>target</th>\n",
       "      <th>next_color_code</th>\n",
       "      <th>note_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>927</td>\n",
       "      <td>PO Contract value in the General Section does ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>HA80E5771</td>\n",
       "      <td>CPFF</td>\n",
       "      <td>1</td>\n",
       "      <td>Production</td>\n",
       "      <td>NORTHROP GRUMMAN SYSTEMS CORPORATION</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>000001.2017.12.000927</td>\n",
       "      <td>PO Contract value in the General Section does ...</td>\n",
       "      <td>reflect</td>\n",
       "      <td>total basic</td>\n",
       "      <td>PO Contract value the General Section the Tota...</td>\n",
       "      <td>reflect total basic po contract value the gene...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OLGASim LOS Bias Error Insertion8</td>\n",
       "      <td>2018</td>\n",
       "      <td>02</td>\n",
       "      <td>HA80E5771</td>\n",
       "      <td>CPFF</td>\n",
       "      <td>1</td>\n",
       "      <td>Production</td>\n",
       "      <td>NORTHROP GRUMMAN SYSTEMS CORPORATION</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>000001.2018.02.000001</td>\n",
       "      <td>OLGASim LOS Bias Error Insertion8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>OLGASim LOS Bias Error Insertion8</td>\n",
       "      <td>olgasim los bias error insertion8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>conduct initial delivery 4 MCSB-2 IT&amp;E capabil...</td>\n",
       "      <td>2018</td>\n",
       "      <td>02</td>\n",
       "      <td>HA80E5771</td>\n",
       "      <td>CPFF</td>\n",
       "      <td>1</td>\n",
       "      <td>Production</td>\n",
       "      <td>NORTHROP GRUMMAN SYSTEMS CORPORATION</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>000001.2018.02.000002</td>\n",
       "      <td>conduct initial delivery 4 MCSB-2 IT&amp;E capabil...</td>\n",
       "      <td>conduct</td>\n",
       "      <td>initial complete</td>\n",
       "      <td>initial delivery 4 MCSB-2</td>\n",
       "      <td>conduct initial complete initial delivery 4 mc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>927;1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SID  Scorecard_Detail_Note_SID  \\\n",
       "0    1                        927   \n",
       "1    1                          1   \n",
       "2    1                          2   \n",
       "\n",
       "                                      Scorecard_Note  Note_Year Note_Month  \\\n",
       "0  PO Contract value in the General Section does ...       2017         12   \n",
       "1                  OLGASim LOS Bias Error Insertion8       2018         02   \n",
       "2  conduct initial delivery 4 MCSB-2 IT&E capabil...       2018         02   \n",
       "\n",
       "   PO_Number PO_Contract_Type  PO_Complexity_Level PO_Lifecycle_Phase  \\\n",
       "0  HA80E5771             CPFF                    1         Production   \n",
       "1  HA80E5771             CPFF                    1         Production   \n",
       "2  HA80E5771             CPFF                    1         Production   \n",
       "\n",
       "                          Supplier_Name  ... Archive_Indicator  \\\n",
       "0  NORTHROP GRUMMAN SYSTEMS CORPORATION  ...                 Y   \n",
       "1  NORTHROP GRUMMAN SYSTEMS CORPORATION  ...                 Y   \n",
       "2  NORTHROP GRUMMAN SYSTEMS CORPORATION  ...                 Y   \n",
       "\n",
       "                 sid_key                                     pre_scrub_text  \\\n",
       "0  000001.2017.12.000927  PO Contract value in the General Section does ...   \n",
       "1  000001.2018.02.000001                  OLGASim LOS Bias Error Insertion8   \n",
       "2  000001.2018.02.000002  conduct initial delivery 4 MCSB-2 IT&E capabil...   \n",
       "\n",
       "     verbs        adjectives  \\\n",
       "0  reflect       total basic   \n",
       "1                              \n",
       "2  conduct  initial complete   \n",
       "\n",
       "                                         noun_chunks  \\\n",
       "0  PO Contract value the General Section the Tota...   \n",
       "1                  OLGASim LOS Bias Error Insertion8   \n",
       "2                          initial delivery 4 MCSB-2   \n",
       "\n",
       "                                          main_words  target  next_color_code  \\\n",
       "0  reflect total basic po contract value the gene...       0                0   \n",
       "1                  olgasim los bias error insertion8       0                0   \n",
       "2  conduct initial complete initial delivery 4 mc...       0                0   \n",
       "\n",
       "  note_history  \n",
       "0               \n",
       "1          927  \n",
       "2        927;1  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the enriched dataframe\n",
    "print(\"=\" * 60)\n",
    "print(\"ENRICHED DATAFRAME\")\n",
    "print(\"=\" * 60)\n",
    "if state.enriched_df is not None:\n",
    "    print(f\"Shape: {state.enriched_df.shape}\")\n",
    "    print(f\"Columns: {list(state.enriched_df.columns[:10])}...\")\n",
    "    display(state.enriched_df.head(3))\n",
    "else:\n",
    "    print(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SID HISTORY WINDOWS (Training Data)\n",
      "============================================================\n",
      "Shape: (25964, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>trainable</th>\n",
       "      <th>trainable_h2</th>\n",
       "      <th>target</th>\n",
       "      <th>target_h2</th>\n",
       "      <th>color_set</th>\n",
       "      <th>all_green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GGGG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sid  trainable  trainable_h2  target  target_h2 color_set  all_green\n",
       "0    1       True          True       0          0      GGGG          1\n",
       "1    1       True          True       0          0      GGGG          1\n",
       "2    1       True          True       0          0      GGGG          1\n",
       "3    1       True          True       0          0      GGGG          1\n",
       "4    1       True          True       0          0      GGGG          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H1 Trainable rows: 25048\n",
      "H2 Trainable rows: 24193\n"
     ]
    }
   ],
   "source": [
    "# Check the SID history windows\n",
    "print(\"=\" * 60)\n",
    "print(\"SID HISTORY WINDOWS (Training Data)\")\n",
    "print(\"=\" * 60)\n",
    "if state.sid_df is not None:\n",
    "    print(f\"Shape: {state.sid_df.shape}\")\n",
    "    \n",
    "    # Show key columns\n",
    "    key_cols = ['sid', 'trainable', 'trainable_h2', 'target', 'target_h2', 'color_set', 'all_green']\n",
    "    available_cols = [c for c in key_cols if c in state.sid_df.columns]\n",
    "    display(state.sid_df[available_cols].head(5))\n",
    "    \n",
    "    # Stats\n",
    "    print(f\"\\nH1 Trainable rows: {state.sid_df['trainable'].sum()}\")\n",
    "    if 'trainable_h2' in state.sid_df.columns:\n",
    "        print(f\"H2 Trainable rows: {state.sid_df['trainable_h2'].sum()}\")\n",
    "else:\n",
    "    print(\"Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL RESULTS BY HORIZON\n",
      "============================================================\n",
      "\n",
      "--- Horizon H1 ---\n",
      "Best Model Key: H1 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "Accuracy: 0.9651\n",
      "False Negatives: 83\n",
      "Class Weights: {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "\n",
      "--- Horizon H2 ---\n",
      "Best Model Key: H2 | complete_main_words_only | no_downsample_weighted | count | Weights {0: 0.5, 1: 1.35, 2: 1.15}\n",
      "Accuracy: 0.9731\n",
      "False Negatives: 57\n",
      "Class Weights: {0: 0.5, 1: 1.35, 2: 1.15}\n"
     ]
    }
   ],
   "source": [
    "# Check model results by horizon\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL RESULTS BY HORIZON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for h_int, key in state.best_model_key_by_horizon.items():\n",
    "    print(f\"\\n--- Horizon H{h_int} ---\")\n",
    "    print(f\"Best Model Key: {key}\")\n",
    "    \n",
    "    model_info = state.best_model_by_horizon.get(h_int, {})\n",
    "    if model_info:\n",
    "        print(f\"Accuracy: {model_info.get('accuracy', 'N/A'):.4f}\")\n",
    "        print(f\"False Negatives: {model_info.get('total_false_negatives', 'N/A')}\")\n",
    "        print(f\"Class Weights: {model_info.get('class_weights', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREDICTIONS\n",
      "============================================================\n",
      "Complete DataFrame shape: (29281, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid_key</th>\n",
       "      <th>predicted_color</th>\n",
       "      <th>prob_green</th>\n",
       "      <th>prob_yellow</th>\n",
       "      <th>prob_red</th>\n",
       "      <th>predicted_color_h2</th>\n",
       "      <th>prob_green_h2</th>\n",
       "      <th>prob_yellow_h2</th>\n",
       "      <th>prob_red_h2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.2017.12.000927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001.2018.02.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001.2018.02.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001.2018.02.000003</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.981678</td>\n",
       "      <td>0.017538</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.996945</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001.2018.02.000004</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.988801</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.992948</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.000846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000001.2018.02.000005</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.988190</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.987267</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000001.2018.02.000006</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.976389</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.976663</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.003771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000001.2018.06.002229</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.968093</td>\n",
       "      <td>0.029249</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.971008</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0.003054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000001.2019.01.001001</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.987039</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.987257</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000001.2019.01.002228</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.971077</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.035288</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sid_key predicted_color  prob_green  prob_yellow  prob_red  \\\n",
       "0  000001.2017.12.000927             NaN         NaN          NaN       NaN   \n",
       "1  000001.2018.02.000001             NaN         NaN          NaN       NaN   \n",
       "2  000001.2018.02.000002             NaN         NaN          NaN       NaN   \n",
       "3  000001.2018.02.000003           Green    0.981678     0.017538  0.000784   \n",
       "4  000001.2018.02.000004           Green    0.988801     0.010300  0.000900   \n",
       "5  000001.2018.02.000005           Green    0.988190     0.011203  0.000607   \n",
       "6  000001.2018.02.000006           Green    0.976389     0.021143  0.002468   \n",
       "7  000001.2018.06.002229           Green    0.968093     0.029249  0.002658   \n",
       "8  000001.2019.01.001001           Green    0.987039     0.011908  0.001053   \n",
       "9  000001.2019.01.002228           Green    0.971077     0.027122  0.001801   \n",
       "\n",
       "  predicted_color_h2  prob_green_h2  prob_yellow_h2  prob_red_h2  \n",
       "0                NaN            NaN             NaN          NaN  \n",
       "1                NaN            NaN             NaN          NaN  \n",
       "2                NaN            NaN             NaN          NaN  \n",
       "3              Green       0.996945        0.002598     0.000457  \n",
       "4              Green       0.992948        0.006205     0.000846  \n",
       "5              Green       0.987267        0.012031     0.000702  \n",
       "6              Green       0.976663        0.019566     0.003771  \n",
       "7              Green       0.971008        0.025938     0.003054  \n",
       "8              Green       0.987257        0.012049     0.000695  \n",
       "9              Green       0.963485        0.035288     0.001227  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H1 Prediction Distribution:\n",
      "predicted_color\n",
      "Green     20864\n",
      "Yellow     4087\n",
      "Red        1013\n",
      "Name: count, dtype: int64\n",
      "\n",
      "H2 Prediction Distribution:\n",
      "predicted_color_h2\n",
      "Green     20831\n",
      "Yellow     4128\n",
      "Red        1005\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check predictions\n",
    "print(\"=\" * 60)\n",
    "print(\"PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if state.complete_df is not None:\n",
    "    print(f\"Complete DataFrame shape: {state.complete_df.shape}\")\n",
    "    \n",
    "    # Show prediction columns\n",
    "    pred_cols = ['sid_key', 'predicted_color', 'prob_green', 'prob_yellow', 'prob_red']\n",
    "    if 'predicted_color_h2' in state.complete_df.columns:\n",
    "        pred_cols.extend(['predicted_color_h2', 'prob_green_h2', 'prob_yellow_h2', 'prob_red_h2'])\n",
    "    \n",
    "    available_cols = [c for c in pred_cols if c in state.complete_df.columns]\n",
    "    display(state.complete_df[available_cols].head(10))\n",
    "    \n",
    "    # Prediction distribution\n",
    "    if 'predicted_color' in state.complete_df.columns:\n",
    "        print(\"\\nH1 Prediction Distribution:\")\n",
    "        print(state.complete_df['predicted_color'].value_counts())\n",
    "    \n",
    "    if 'predicted_color_h2' in state.complete_df.columns:\n",
    "        print(\"\\nH2 Prediction Distribution:\")\n",
    "        print(state.complete_df['predicted_color_h2'].value_counts())\n",
    "else:\n",
    "    print(\"Not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Manual Step-by-Step Execution (Alternative)\n",
    "\n",
    "If you prefer more control, you can run each component manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual execution example (commented out - uncomment to use)\n",
    "\"\"\"\n",
    "# Step 1: Create config and state\n",
    "config = ScoreCardConfig(\n",
    "    sql_download=False,  # Load from ES instead\n",
    "    build_models=True,\n",
    ")\n",
    "state = ScoreCardState(config=config)\n",
    "\n",
    "# Step 2: Initialize connections\n",
    "conn = ConnectionManager(config=config, state=state)\n",
    "\n",
    "# Step 3: Load data from Elasticsearch\n",
    "state.enriched_df = conn.load_from_es(index_name=\"scorecard_enriched\", id_col=\"sid_key\")\n",
    "state.sid_df = conn.load_from_es(index_name=\"scorecard_sid_history\")\n",
    "\n",
    "# Step 4: Train models\n",
    "modeler = ScoreCardModeling(config=config, state=state, conn=conn)\n",
    "modeler.build_model_grid()\n",
    "\n",
    "# Train H1\n",
    "modeler.find_best_model(horizon=Horizon.H1)\n",
    "modeler.predict_with_best_model(state.sid_df, horizon=Horizon.H1)\n",
    "\n",
    "# Train H2\n",
    "modeler.find_best_model(horizon=Horizon.H2)\n",
    "modeler.predict_with_best_model(state.sid_df, horizon=Horizon.H2)\n",
    "\n",
    "# Merge predictions\n",
    "modeler.merge_data()\n",
    "\n",
    "# Step 5: Generate GPT justifications (optional)\n",
    "rag = ScoreCardRag(config=config, state=state, conn=conn)\n",
    "rag.embed_and_index_notes()\n",
    "rag.generate_justifications(anchor_sid_key=\"000123.2024.06.000456\", printer=True)\n",
    "\"\"\"\n",
    "print(\"Manual execution example is available in comments above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAG and GPT Justifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a GPT justification for a specific note\n",
    "# (Requires RAG index to be built first)\n",
    "\n",
    "if state.complete_df is not None and len(state.complete_df) > 0:\n",
    "    # Pick a sample sid_key\n",
    "    sample_sid_key = state.complete_df['sid_key'].iloc[0]\n",
    "    print(f\"Sample sid_key: {sample_sid_key}\")\n",
    "    \n",
    "    # Uncomment to generate justification:\n",
    "    # rag.generate_justifications(anchor_sid_key=sample_sid_key, printer=True)\n",
    "else:\n",
    "    print(\"No data available for RAG demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = {\n",
    "    \"Enriched Notes\": len(state.enriched_df) if state.enriched_df is not None else 0,\n",
    "    \"Training Windows\": len(state.sid_df) if state.sid_df is not None else 0,\n",
    "    \"Complete DataFrame\": len(state.complete_df) if state.complete_df is not None else 0,\n",
    "    \"Models Trained\": len(state.best_model_key_by_horizon),\n",
    "    \"Horizons\": list(state.best_model_key_by_horizon.keys()),\n",
    "}\n",
    "\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nPipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
