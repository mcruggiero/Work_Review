{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreCard Complete Pipeline\n",
    "\n",
    "End-to-end pipeline including:\n",
    "1. **Data Download** - SQL Server\n",
    "2. **NLP Enrichment** - spaCy text processing\n",
    "3. **Model Training** - H1/H2 horizon predictions\n",
    "4. **Elasticsearch Indexing** - RAG embeddings\n",
    "5. **GPT Enrichment** - Generate justifications for predictions\n",
    "6. **SQL Upload** - Push results back to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scorecard import (\n",
    "    # Core\n",
    "    ScoreCardConfig,\n",
    "    ScoreCardState,\n",
    "    ConnectionManager,\n",
    "    ScoreCardPipeline,\n",
    "    ScoreCardRag,\n",
    "    run_pipeline,\n",
    "    # Upload\n",
    "    upload_predictions_to_sql,\n",
    "    build_upload_table,\n",
    "    # State persistence\n",
    "    save_state,\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = ScoreCardConfig(\n",
    "    # Data source\n",
    "    sql_download=True,\n",
    "    \n",
    "    # Pipeline stages\n",
    "    enable_nlp=True,\n",
    "    build_models=True,\n",
    "    run_predictions=True,\n",
    "    build_rag=True,\n",
    "    \n",
    "    # Model keys (use predetermined for speed)\n",
    "    default_model_key_h1=\"complete_main_words_only | no_downsample_weighted | count | {0: 0.5, 1: 1.35, 2: 1.15}\",\n",
    "    default_model_key_h2=\"complete_main_words_only | no_downsample_weighted | count | {0: 0.5, 1: 1.35, 2: 1.15}\",\n",
    "    \n",
    "    training_length=5,\n",
    ")\n",
    "\n",
    "print(\"Configuration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Run Core Pipeline (NLP + Modeling + ES Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "# This handles: SQL download, NLP, model training, predictions, RAG embeddings\n",
    "state, pipeline, rag = run_pipeline(\n",
    "    sql_download=config.sql_download,\n",
    "    enable_nlp=config.enable_nlp,\n",
    "    build_models=config.build_models,\n",
    "    run_predictions=config.run_predictions,\n",
    "    build_rag=config.build_rag,\n",
    ")\n",
    "\n",
    "# Get connection manager reference\n",
    "conn = pipeline.conn\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORE PIPELINE COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary\n",
    "print(f\"Enriched notes: {len(state.enriched_df):,}\")\n",
    "print(f\"Predictions: {len(state.predictions_df):,}\")\n",
    "print(f\"Complete dataset: {len(state.complete_df):,}\")\n",
    "for h, key in state.best_model_key_by_horizon.items():\n",
    "    print(f\"H{h} model: {key[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. GPT Enrichment - Generate Justifications\n",
    "\n",
    "This step calls GPT to explain WHY the model made each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Enrichment settings\n",
    "GPT_LIMIT = None          # Set to None for ALL notes, or a number to limit (e.g., 100)\n",
    "GPT_MAX_WORKERS = 4       # Parallel threads for GPT calls\n",
    "GPT_BACKOFF = 1.5         # Backoff multiplier for retries\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GPT ENRICHMENT CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Limit: {GPT_LIMIT if GPT_LIMIT else 'ALL NOTES'}\")\n",
    "print(f\"Max workers: {GPT_MAX_WORKERS}\")\n",
    "print(f\"Total notes to process: {len(state.complete_df) if GPT_LIMIT is None else min(GPT_LIMIT, len(state.complete_df))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure RAG object is ready\n",
    "if rag is None:\n",
    "    print(\"Creating RAG object...\")\n",
    "    rag = ScoreCardRag(config=config, state=state, conn=conn)\n",
    "    \n",
    "print(f\"RAG index: {config.rag_index}\")\n",
    "print(f\"GPT model: {rag.gpt_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GPT justification pass\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING GPT ENRICHMENT\")\n",
    "print(\"=\"*60)\n",
    "print(\"This will generate GPT explanations for each prediction...\")\n",
    "print(\"(This may take a while depending on the number of notes)\\n\")\n",
    "\n",
    "rag.run_gpt_justification_pass(\n",
    "    limit=GPT_LIMIT,\n",
    "    max_attempts=6,\n",
    "    backoff=GPT_BACKOFF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPT enrichment by sampling a few\n",
    "print(\"=\"*60)\n",
    "print(\"GPT ENRICHMENT VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "es = conn.es_client\n",
    "\n",
    "# Check how many have justifications\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\"exists\": {\"field\": \"justification\"}},\n",
    "            \"must_not\": {\"term\": {\"justification.keyword\": \"\"}}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "result = es.count(index=config.rag_index, body=query)\n",
    "print(f\"\\nNotes with GPT justifications: {result['count']:,}\")\n",
    "\n",
    "# Show a sample\n",
    "sample_query = {\n",
    "    \"size\": 3,\n",
    "    \"query\": query[\"query\"],\n",
    "    \"_source\": [\"sid_key\", \"SID\", \"justification\"]\n",
    "}\n",
    "samples = es.search(index=config.rag_index, body=sample_query)\n",
    "\n",
    "print(\"\\nSample justifications:\")\n",
    "for hit in samples['hits']['hits']:\n",
    "    src = hit['_source']\n",
    "    print(f\"\\n--- {src['sid_key']} (SID {src['SID']}) ---\")\n",
    "    print(src.get('justification', 'N/A')[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Prepare Upload DataFrame\n",
    "\n",
    "Merge predictions with GPT justifications for SQL upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetch_all_justifications(es, index, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Fetch all justifications from ES using scroll API.\n",
    "    \"\"\"\n",
    "    justifications = {}\n",
    "    \n",
    "    query = {\n",
    "        \"size\": batch_size,\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"_source\": [\"sid_key\", \"justification\"]\n",
    "    }\n",
    "    \n",
    "    # Initial search\n",
    "    result = es.search(index=index, body=query, scroll='2m')\n",
    "    scroll_id = result['_scroll_id']\n",
    "    hits = result['hits']['hits']\n",
    "    \n",
    "    while hits:\n",
    "        for hit in hits:\n",
    "            src = hit['_source']\n",
    "            sid_key = src.get('sid_key')\n",
    "            justification = src.get('justification', '')\n",
    "            if sid_key and justification:\n",
    "                justifications[sid_key] = justification\n",
    "        \n",
    "        # Get next batch\n",
    "        result = es.scroll(scroll_id=scroll_id, scroll='2m')\n",
    "        hits = result['hits']['hits']\n",
    "    \n",
    "    # Clear scroll\n",
    "    es.clear_scroll(scroll_id=scroll_id)\n",
    "    \n",
    "    return justifications\n",
    "\n",
    "print(\"Fetching all GPT justifications from ES...\")\n",
    "justifications = fetch_all_justifications(conn.es_client, config.rag_index)\n",
    "print(f\"Retrieved {len(justifications):,} justifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge justifications into predictions DataFrame\n",
    "upload_df = state.complete_df.copy()\n",
    "\n",
    "# Add GPT justification column\n",
    "upload_df['GPT_Justification'] = upload_df['sid_key'].map(justifications).fillna('')\n",
    "\n",
    "print(f\"Upload DataFrame: {upload_df.shape}\")\n",
    "print(f\"Notes with justifications: {(upload_df['GPT_Justification'] != '').sum():,}\")\n",
    "\n",
    "# Show sample\n",
    "cols_to_show = ['sid_key', 'SID', 'predicted_color', 'prob_green', 'prob_yellow', 'prob_red', 'GPT_Justification']\n",
    "available_cols = [c for c in cols_to_show if c in upload_df.columns]\n",
    "upload_df[available_cols].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. SQL Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the upload table with proper schema\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARING SQL UPLOAD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "upload_table = build_upload_table(upload_df)\n",
    "print(f\"\\nUpload table shape: {upload_table.shape}\")\n",
    "print(f\"Columns: {list(upload_table.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview before upload\n",
    "print(\"\\nUpload Preview (first 5 rows):\")\n",
    "upload_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRY RUN - Preview what would be uploaded\n",
    "print(\"=\"*60)\n",
    "print(\"SQL UPLOAD - DRY RUN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "upload_predictions_to_sql(\n",
    "    df=upload_table,\n",
    "    config=config,\n",
    "    table_name=\"Model_Predictions\",\n",
    "    dry_run=True,  # <-- Set to False for actual upload\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL UPLOAD - Uncomment to execute\n",
    "# print(\"=\"*60)\n",
    "# print(\"SQL UPLOAD - EXECUTING\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# upload_predictions_to_sql(\n",
    "#     df=upload_table,\n",
    "#     config=config,\n",
    "#     table_name=\"Model_Predictions\",\n",
    "#     dry_run=False,  # <-- Actual upload!\n",
    "# )\n",
    "\n",
    "# print(\"\\nUpload complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Save State (Optional)\n",
    "\n",
    "Save the pipeline state for later analysis without re-running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state for later use\n",
    "save_state(\n",
    "    state=state,\n",
    "    pipeline=pipeline,\n",
    "    rag=rag,\n",
    "    config=config,\n",
    "    conn=conn,\n",
    "    path=\"./pipeline_state.pkl\",\n",
    "    include_models=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Pipeline Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COMPLETE PIPELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. DATA\")\n",
    "print(f\"   - Raw notes downloaded: {len(state.details_df):,}\")\n",
    "print(f\"   - Enriched notes: {len(state.enriched_df):,}\")\n",
    "\n",
    "print(f\"\\n2. MODELS\")\n",
    "for h, key in state.best_model_key_by_horizon.items():\n",
    "    print(f\"   - H{h}: {key[:50]}...\")\n",
    "\n",
    "print(f\"\\n3. PREDICTIONS\")\n",
    "print(f\"   - Total predictions: {len(state.complete_df):,}\")\n",
    "for h, df in state.predictions_df_by_horizon.items():\n",
    "    if df is not None:\n",
    "        print(f\"   - H{h} predictions: {len(df):,}\")\n",
    "\n",
    "print(f\"\\n4. GPT ENRICHMENT\")\n",
    "print(f\"   - Notes with justifications: {len(justifications):,}\")\n",
    "\n",
    "print(f\"\\n5. UPLOAD\")\n",
    "print(f\"   - Upload table rows: {len(upload_table):,}\")\n",
    "print(f\"   - Status: Ready (run actual upload cell to execute)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
